{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54caaad7-a554-48cb-8f28-f5e4ff450258",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# GOLD LAYER\n",
    "\n",
    "## General Info\n",
    "  | Info | Details |\n",
    "  |---------|------|\n",
    "  |Table Name | TBD|\n",
    "  |From | Azure |\n",
    "\n",
    "## Update timeline\n",
    "|Date | Developed/altered by: | Comment |\n",
    "|:------:|--------|-------|\n",
    "|2025/01/23|Luca Ainstein|Project Data Ingestion|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5554e2c-9ba3-4fba-89b4-71298e662321",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4672d1fc-ff32-462b-86d3-02bcbd2ee870",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Import of libs\n",
    "\n",
    "from pyspark.sql.functions import current_date, current_timestamp, expr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37ad3fbe-3d97-4aef-be82-3f7cad00ee0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Cluster Conection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6583fb4-f69a-4918-a3ff-a2c6adf255df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration applied successfully.\n"
     ]
    }
   ],
   "source": [
    "### There is the alternative of using the conection directly on the cluster creation. However, since the Databricks Community Cloud only allows 1-2 hours of inactivity before deleting the cluster, it is better to create the connection on the code. \n",
    "\n",
    "# Set up the configurations for Azure Data Lake Storage Gen2 using OAuth authentication\n",
    "configs = {\n",
    "    \"fs.azure.account.auth.type.dlsprojetofixo.dfs.core.windows.net\": \"OAuth\",\n",
    "    \"fs.azure.account.oauth.provider.type.dlsprojetofixo.dfs.core.windows.net\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n",
    "    \"fs.azure.account.oauth2.client.id.dlsprojetofixo.dfs.core.windows.net\": \"238b3ff5-2a4b-49a0-838e-61aea5e55f0a\",\n",
    "    \"fs.azure.account.oauth2.client.secret.dlsprojetofixo.dfs.core.windows.net\": \"~h.8Q~XwXAMBiXDY69nUxONcfoO49RweWIPELdkM\",\n",
    "    \"fs.azure.account.oauth2.client.endpoint.dlsprojetofixo.dfs.core.windows.net\": \"https://login.microsoftonline.com/d16f0536-3c2f-4035-887f-8949bacfacfd/oauth2/token\"\n",
    "}\n",
    "\n",
    "# Apply the configurations to Spark\n",
    "for key, value in configs.items():\n",
    "    spark.conf.set(key, value)\n",
    "\n",
    "# Verify the configuration\n",
    "print(\"Configuration applied successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91362e30-03ff-40fe-a150-82a0eaed5e4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Star Schema: https://excalidraw.com/#json=i0qNHJZYtOEOmCDmN8p18,CaEi5WFnMMP_DpCn9NbHLA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b7cd41b0-a034-41ac-a32a-c81efa223685",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Table `fact_orders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d812b00-1c8c-43a8-bdd1-1dc502c0892f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema is created!\nOptimization gold.fact_orders completed!\n"
     ]
    }
   ],
   "source": [
    "### GOLD Table creation\n",
    "\n",
    "## Table Creation\n",
    "\n",
    "df_fo = spark.sql(\n",
    "f\"\"\"\n",
    "SELECT\n",
    "  OrderID,\n",
    "  CustomerID,\n",
    "  ItemID,\n",
    "  OrderDate,\n",
    "  ItemQuantity,\n",
    "  TotalAmount,\n",
    "  Status\n",
    "FROM\n",
    "  silver.sales;\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "df_fo = df_fo.withColumn(\"load_time_GMT\", current_timestamp())\n",
    "# Note that it is GMT. Please see Layer bronze for further details.\n",
    "\n",
    "## Var Naming\n",
    "schema_layer = \"gold\"\n",
    "table_name = \"fact_orders\"\n",
    "\n",
    "## Path def\n",
    "path_target = 'abfss://gold@dlsprojetofixo.dfs.core.windows.net/fact_orders_lucaainstein'\n",
    "\n",
    "## Database Creation\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS gold\")\n",
    "df_fo.write \\\n",
    "    .format('delta') \\\n",
    "    .mode('overwrite') \\\n",
    "    .option('path', path_target) \\\n",
    "    .option('overwriteSchema', 'true') \\\n",
    "    .saveAsTable(f'{schema_layer}.{table_name}')\n",
    "print(\"Schema is created!\")\n",
    "\n",
    "spark.sql(f\"OPTIMIZE {schema_layer}.{table_name}\")\n",
    "print(\"Optimization \" + f'{schema_layer}.{table_name}' + \" completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9907dfab-a329-4563-a429-464141f807ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Table `Customer_DIM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a2a9f63-e3ef-441e-818b-4e24594b2648",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema is created!\nOptimization gold.Customer_DIM completed!\n"
     ]
    }
   ],
   "source": [
    "### GOLD Table creation\n",
    "\n",
    "## Table Creation\n",
    "\n",
    "df = spark.sql(\n",
    "f\"\"\"\n",
    "SELECT\n",
    "  CustomerID,\n",
    "  Name,\n",
    "  PhoneNumber,\n",
    "  Age\n",
    "FROM\n",
    "  silver.sales;\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "df = df.withColumn(\"load_time_GMT\", current_timestamp())\n",
    "# Note that it is GMT. Please see Layer bronze for further details.\n",
    "\n",
    "## Var Naming\n",
    "schema_layer = \"gold\"\n",
    "table_name = \"Customer_DIM\"\n",
    "\n",
    "## Path def\n",
    "path_target = 'abfss://gold@dlsprojetofixo.dfs.core.windows.net/Customer_DIM_lucaainstein'\n",
    "\n",
    "## Database Creation\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS gold\")\n",
    "df.write \\\n",
    "    .format('delta') \\\n",
    "    .mode('overwrite') \\\n",
    "    .option('path', path_target) \\\n",
    "    .option('overwriteSchema', 'true') \\\n",
    "    .saveAsTable(f'{schema_layer}.{table_name}')\n",
    "print(\"Schema is created!\")\n",
    "\n",
    "spark.sql(f\"OPTIMIZE {schema_layer}.{table_name}\")\n",
    "print(\"Optimization \" + f'{schema_layer}.{table_name}' + \" completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15dcaa5b-7a5f-4f76-9372-d7333f32245e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Table `Product_DIM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e66bb9c-0ae2-42dc-87d3-2e33ea1a8ff1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema is created!\nOptimization gold.Product_DIM completed!\n"
     ]
    }
   ],
   "source": [
    "### GOLD Table creation\n",
    "\n",
    "## Table Creation\n",
    "\n",
    "df = spark.sql(\n",
    "f\"\"\"\n",
    "SELECT\n",
    "  ItemID,\n",
    "  ItemPrice,\n",
    "  ItemProductName\n",
    "FROM\n",
    "  silver.sales;\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "df = df.withColumn(\"load_time_GMT\", current_timestamp())\n",
    "# Note that it is GMT. Please see Layer bronze for further details.\n",
    "\n",
    "## Var Naming\n",
    "schema_layer = \"gold\"\n",
    "table_name = \"Product_DIM\"\n",
    "\n",
    "## Path def\n",
    "path_target = 'abfss://gold@dlsprojetofixo.dfs.core.windows.net/Product_DIM_lucaainstein'\n",
    "\n",
    "## Database Creation\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS gold\")\n",
    "df.write \\\n",
    "    .format('delta') \\\n",
    "    .mode('overwrite') \\\n",
    "    .option('path', path_target) \\\n",
    "    .option('overwriteSchema', 'true') \\\n",
    "    .saveAsTable(f'{schema_layer}.{table_name}')\n",
    "print(\"Schema is created!\")\n",
    "\n",
    "spark.sql(f\"OPTIMIZE {schema_layer}.{table_name}\")\n",
    "print(\"Optimization \" + f'{schema_layer}.{table_name}' + \" completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef8fd3c7-0e1a-40e0-b501-3546454a53c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Table `Shipping_DIM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c3ce259-3cb3-4a07-8b54-39d9265b4133",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema is created!\nOptimization gold.Shipping_DIM completed!\n"
     ]
    }
   ],
   "source": [
    "### GOLD Table creation\n",
    "\n",
    "## Table Creation\n",
    "\n",
    "df = spark.sql(\n",
    "f\"\"\"\n",
    "SELECT\n",
    "  OrderID,\n",
    "  Street,\n",
    "  City,\n",
    "  State,\n",
    "  Country,\n",
    "  PostalCode\n",
    "FROM\n",
    "  silver.sales;\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "df = df.withColumn(\"load_time_GMT\", current_timestamp())\n",
    "# Note that it is GMT. Please see Layer bronze for further details.\n",
    "\n",
    "## Var Naming\n",
    "schema_layer = \"gold\"\n",
    "table_name = \"Shipping_DIM\"\n",
    "\n",
    "## Path def\n",
    "path_target = 'abfss://gold@dlsprojetofixo.dfs.core.windows.net/Shipping_DIM_lucaainstein'\n",
    "\n",
    "## Database Creation\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS gold\")\n",
    "df.write \\\n",
    "    .format('delta') \\\n",
    "    .mode('overwrite') \\\n",
    "    .option('path', path_target) \\\n",
    "    .option('overwriteSchema', 'true') \\\n",
    "    .saveAsTable(f'{schema_layer}.{table_name}')\n",
    "print(\"Schema is created!\")\n",
    "\n",
    "spark.sql(f\"OPTIMIZE {schema_layer}.{table_name}\")\n",
    "print(\"Optimization \" + f'{schema_layer}.{table_name}' + \" completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e58a24bb-a414-452f-9315-8d6a8e5e7120",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Table `Date_DIM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d065df0-be96-4107-9310-d20bff41842f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema is created!\nOptimization gold.Date_DIM completed!\n"
     ]
    }
   ],
   "source": [
    "### GOLD Table creation\n",
    "\n",
    "## Table Creation\n",
    "\n",
    "df = spark.sql(\n",
    "f\"\"\"\n",
    "SELECT\n",
    "  OrderDate,\n",
    "  EXTRACT(YEAR from OrderDate) AS OrderYear,\n",
    "  EXTRACT(MONTH from OrderDate) AS OrderMonth,\n",
    "  EXTRACT(DAY from OrderDate) AS OrderDay,\n",
    "  WEEKDAY(OrderDate) AS OrderWeekday\n",
    "FROM\n",
    "  silver.sales;\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "df = df.withColumn(\"load_time_GMT\", current_timestamp())\n",
    "# Note that it is GMT. Please see Layer bronze for further details.\n",
    "\n",
    "## Var Naming\n",
    "schema_layer = \"gold\"\n",
    "table_name = \"Date_DIM\"\n",
    "\n",
    "## Path def\n",
    "path_target = 'abfss://gold@dlsprojetofixo.dfs.core.windows.net/Data_DIM_lucaainstein'\n",
    "\n",
    "## Database Creation\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS gold\")\n",
    "df.write \\\n",
    "    .format('delta') \\\n",
    "    .mode('overwrite') \\\n",
    "    .option('path', path_target) \\\n",
    "    .option('overwriteSchema', 'true') \\\n",
    "    .saveAsTable(f'{schema_layer}.{table_name}')\n",
    "print(\"Schema is created!\")\n",
    "\n",
    "spark.sql(f\"OPTIMIZE {schema_layer}.{table_name}\")\n",
    "print(\"Optimization \" + f'{schema_layer}.{table_name}' + \" completed!\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1560306170477523,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "gold_layer_config",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
